{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC Scraper\n",
    "This notebook scrapes SEC 10-K filings for specific companies and extracts their risk factor sections. The extracted data is saved into CSV files for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will create a scraper to extract risk factor sections from SEC 10-K filings. The process involves:\n",
    "1. Retrieving the Central Index Key (CIK) for a given company ticker.\n",
    "2. Getting the list of 10-K filings for the CIK.\n",
    "3. Downloading and parsing the risk factors section from the filings.\n",
    "4. Saving the extracted data into CSV files.\n",
    "\n",
    "## Import Libraries\n",
    "We start by importing necessary libraries. We will use:\n",
    "- `os` for directory and file operations.\n",
    "- `requests` for making HTTP requests.\n",
    "- `BeautifulSoup` from the `bs4` package for parsing HTML content.\n",
    "- `pandas` for handling data in DataFrame format.\n",
    "- `time` for adding delays between requests to avoid server overload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Define the base URL for the SEC EDGAR website\n",
    "BASE_URL = \"https://www.sec.gov\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CIK for Ticker\n",
    "The first step is to retrieve the Central Index Key (CIK) for a given company ticker. The CIK is a unique identifier assigned by the SEC to each company. We define a function `get_cik` that takes a company's stock ticker as input and returns its CIK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the CIK (Central Index Key) for a given company ticker\n",
    "def get_cik(ticker):\n",
    "    \"\"\"\n",
    "    This function takes a company's stock ticker as input and returns its CIK.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.sec.gov/cgi-bin/browse-edgar?CIK={ticker}&owner=exclude&action=getcompany\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    cik_tag = soup.find('span', {'class': 'companyName'}).find('a')\n",
    "    \n",
    "    if cik_tag:\n",
    "        cik = cik_tag.text.strip()\n",
    "        return cik\n",
    "    else:\n",
    "        print(f\"CIK not found for ticker: {ticker}\")\n",
    "        return None\n",
    "\n",
    "# Example usage of the function\n",
    "ticker = 'AAPL'\n",
    "cik = get_cik(ticker)\n",
    "print(f\"CIK for {ticker}: {cik}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 10-K Filings for CIK\n",
    "Next, we define a function `get_10k_filings` that retrieves a list of 10-K filings for a given CIK. This function will parse the SEC EDGAR website and collect information about the filings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the list of 10-K filings for a given CIK\n",
    "def get_10k_filings(cik, start=0, count=100):\n",
    "    \"\"\"\n",
    "    This function retrieves a list of 10-K filings for a given CIK.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik}&type=10-K&start={start}&count={count}&owner=exclude&output=atom\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    entries = soup.find_all('entry')\n",
    "    \n",
    "    filings = []\n",
    "    for entry in entries:\n",
    "        filing = {\n",
    "            'title': entry.find('title').text,\n",
    "            'link': entry.find('link')['href'],\n",
    "            'summary': entry.find('summary').text,\n",
    "            'updated': entry.find('updated').text\n",
    "        }\n",
    "        filings.append(filing)\n",
    "    \n",
    "    return filings\n",
    "\n",
    "# Example usage of the function\n",
    "filings = get_10k_filings(cik)\n",
    "print(f\"Found {len(filings)} 10-K filings for CIK {cik}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Risk Factors\n",
    "We define a function `get_risk_factors` that downloads a 10-K filing and extracts the Risk Factors section. The extraction is done by looking for the text between \"Item 1A. Risk Factors\" and the next \"Item\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and parse the risk factors section from a 10-K filing\n",
    "def get_risk_factors(filing_url):\n",
    "    \"\"\"\n",
    "    This function downloads a 10-K filing and extracts the Risk Factors section.\n",
    "    \"\"\"\n",
    "    response = requests.get(filing_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Assuming the Risk Factors section starts with \"Item 1A. Risk Factors\" and ends with the next \"Item\"\n",
    "    start_idx = text.find('Item 1A. Risk Factors')\n",
    "    end_idx = text.find('Item', start_idx + 1)\n",
    "    \n",
    "    if start_idx != -1 and end_idx != -1:\n",
    "        risk_factors = text[start_idx:end_idx].strip()\n",
    "        return risk_factors\n",
    "    else:\n",
    "        print(\"Risk Factors section not found\")\n",
    "        return None\n",
    "\n",
    "# Example usage of the function\n",
    "if filings:\n",
    "    first_filing_url = filings[0]['link']\n",
    "    risk_factors = get_risk_factors(first_filing_url)\n",
    "    print(\"Extracted Risk Factors section:\")\n",
    "    print(risk_factors[:500])  # Print the first 500 characters of the risk factors section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Risk Factors to CSV\n",
    "Once we have extracted the Risk Factors section, we save it to a CSV file using the `save_risk_factors` function. The function creates a directory `sec_risk_factors` and saves the data with a filename based on the company ticker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the risk factors to a CSV file\n",
    "def save_risk_factors(ticker, risk_factors):\n",
    "    \"\"\"\n",
    "    This function saves the extracted risk factors to a CSV file.\n",
    "    \"\"\"\n",
    "    output_dir = 'sec_risk_factors'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, f\"{ticker}_risk_factors.csv\")\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(risk_factors)\n",
    "    \n",
    "    print(f\"Risk factors saved to {output_file}\")\n",
    "\n",
    "# Example usage of the function\n",
    "if risk_factors:\n",
    "    save_risk_factors(ticker, risk_factors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Cell\n",
    "It takes a list of company tickers, retrieves their CIKs, gets their 10-K filings, extracts the Risk Factors sections, and saves them to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main cell to scrape and save risk factors for a list of company tickers\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"Processing ticker: {ticker}\")\n",
    "    cik = get_cik(ticker)\n",
    "    \n",
    "    if cik:\n",
    "        filings = get_10k_filings(cik)\n",
    "        \n",
    "        if filings:\n",
    "            first_filing_url = filings[0]['link']\n",
    "            risk_factors = get_risk_factors(first_filing_url)\n",
    "            \n",
    "            if risk_factors:\n",
    "                save_risk_factors(ticker, risk_factors)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
